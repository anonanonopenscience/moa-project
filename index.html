<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Mixture-of-Attention for Subject-Context Disentanglement in Personalized Image Generation.">
  <meta name="keywords" content="MoA">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Mixture-of-Attention</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/eye.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>
<!-- 
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

       <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div> 
    </div> 

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Mixture-of-Attention for Subject-Context Disentanglement in Personalized Image Generation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://broken">Anonymous Authors</a><sup>1</sup>,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Anonymous Org</span>
          </div>
<!-- 
          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div> -->

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video> -->
      <img src="./static/images/figure/figure.010.jpeg"
           alt="Teaser."/>
      <h2 class="subtitle has-text-centered">
        Mixture-of-Attention (MoA) architecture enables multi-subject personalized generation with subject-context disentanglement.
      </h2>
    </div>
  </div>
  <!-- <div class="columns is-vcentered interpolation-panel">
    <div class="column is-1 has-text-centered">
      <img src="./static/images/figure/figure.010.jpeg"
           alt="Teaser."/>
    </div> -->
</section>


<!-- <section class="hero is-light is-small"> -->
<section class="hero teaser">
  <div class="container is-max-desktop">
  <div class="hero-body">
     <!-- Interpolating. -->
     <div class="content has-text-justified">
      <p class="subtitle has-text-centered">
        Drag to traverse the initial random noise, which changes the context consistently across different subject pairs. 
      </p>
     </div>
     <div class="columns is-vcentered interpolation-panel">
       <div class="column is-3 has-text-centered">
         <img src="./static/interpolation/stacked/0000.png"
              class="interpolation-image"
              alt="Interpolate start reference image."/>
         <p>Start Frame</p>
       </div>
       <div class="column interpolation-video-column">
         <div id="interpolation-image-wrapper">
           Loading...
         </div>
         <input class="slider is-fullwidth is-large is-info"
                id="interpolation-slider"
                step="1" min="0" max="199" value="0" type="range">
       </div>
       <div class="column is-3 has-text-centered">
         <img src="./static/interpolation/stacked/0199.png"
              class="interpolation-image"
              alt="Interpolation end reference image."/>
         <p class="is-bold">End Frame</p>
       </div>
     </div>
     <br/>
<!--     
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-disney0">
          <video poster="" id="disney0" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/perturb_videos/disney_0_small.mov"
            type="video/quicktime">
          </video>
        </div>

        <div class="item item-disney1">
          <video poster="" id="disney1" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/perturb_videos/disney_1_small.mov"
                    type="video/quicktime">
          </video>
        </div>
        <div class="item item-disney0">
          <video poster="" id="disney0" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/perturb_videos/disney_0_small.mov"
            type="video/quicktime">
          </video>
        </div>

        <div class="item item-disney1">
          <video poster="" id="disney1" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/perturb_videos/disney_1_small.mov"
                    type="video/quicktime">
          </video>
        </div> 

         <div class="item item-paris_0">
          <video poster="" id="paris_0" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/perturb_videos/paris_0.mp4"
                    type="video/mp4">
          </video>
        </div>
        
        <div class="item item-paris_2">
          <video poster="" id="paris_2" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/perturb_videos/paris_2.mp4"
                    type="video/mp4">
          </video>
        </div>  -->

      </div>
      
    </div>
   
  </div>
</div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          We introduce a new architecture for personalization of text-to-image diffusion models, coined Mixture-of-Attention (MoA). Inspired by the Mixture-of-Experts mechanism utilized in large language models (LLMs), MoA distributes the generation workload between dual attention pathways: a personalized branch and a non-personalized prior branch.
          MoA is designed to retain the original model's prior by fixing its attention layers in the prior branch, while minimally intervening in the generation process with the personalized branch that learns to embed subjects in the layout and context generated by the prior branch.
          A routing mechanism manages the distribution of pixels in each layer across these branches to optimize the blend of personalized and generic content creation. 
          Once trained, MoA facilitates the creation of high-quality, personalized images featuring multiple subjects with compositions and interactions as diverse as those generated by the original model.
          Crucially, MoA enhances the distinction between the model's pre-existing capability and the newly augmented personalized intervention, thereby offers a more disentangled subject-context control that was previously unattainable.
          </p>
         
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
    <h2 class="title is-3">Method</h2>
  </div>
    <div class="content">
      <!-- <h3 class="title is-3">Key idea</h3> -->
      <p>
        Our key observation is that, existing personalization methods often need to trade-off between "prior preservation" for better prompt consistency and "personalization finetuning" for idenity fidelity.  We augment the attention layer using an architecture inspired by the Mixture-of-Expert (MoE) where a router is introduced to distribute tasks among different experts.  In our case, we keep a "prior expert" frozen during finetuning to preserve the prior, and finetune a personalized expert.
      </p>
      <img src="./static/images/fig/MoA.jpg"
           alt="Fig2."/>
    </div>

      <p>
        This MoA is scattered across all attention layers in a pretrained U-Net, and finetuned on a small dataset (FFHQ).
      </p>
      <img src="./static/images/fig/MoA_T2I.jpg"
           alt="Fig3."/>
    </div>
    <!-- <div class="columns is-centered">

      <div class="column">
        <div class="content">
          <h2 class="title is-3">Visual Effects</h2>
          <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <div class="column">
        <h2 class="title is-3">Matting</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              As a byproduct of our method, we can also solve the matting problem by ignoring
              samples that fall outside of a bounding box during rendering.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div> -->
    <!--/ Matting. -->
  </div>
</section>

<!-- 
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>
 -->

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is built on the <a
            href="https://github.com/nerfies/nerfies.github.io">Nerfies template</a> .
          </p>
         
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
